{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "3. Задача класифікації текстів"
      ],
      "metadata": {
        "id": "wfIZwlJKiulk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Завантаження і підготовка GloVe 6B 100d для Colab ===\n",
        "import os\n",
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "# Створимо папку для GloVe\n",
        "glove_dir = \"/content/glove\"\n",
        "os.makedirs(glove_dir, exist_ok=True)\n",
        "\n",
        "# URL на GloVe 6B на офіційному сайті (можемо скачати через gdown або wget)\n",
        "glove_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "zip_path = os.path.join(glove_dir, \"glove.6B.zip\")\n",
        "\n",
        "# Завантажуємо, якщо ще не скачано\n",
        "if not os.path.exists(zip_path):\n",
        "    !wget -O {zip_path} {glove_url}\n",
        "\n",
        "# Розпаковуємо\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(glove_dir)\n",
        "\n",
        "# Шлях до потрібного файлу 100d\n",
        "glove_path = os.path.join(glove_dir, \"glove.6B.100d.txt\")\n",
        "print(\"GloVe 100d готовий за шляхом:\", glove_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VojjQvOwkg2U",
        "outputId": "81fec871-6e4d-4dba-9bbe-7b67ea98b07f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-18 22:26:11--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-12-18 22:26:12--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-12-18 22:26:12--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘/content/glove/glove.6B.zip’\n",
            "\n",
            "/content/glove/glov 100%[===================>] 822.24M  5.03MB/s    in 2m 41s  \n",
            "\n",
            "2025-12-18 22:28:53 (5.10 MB/s) - ‘/content/glove/glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "GloVe 100d готовий за шляхом: /content/glove/glove.6B.100d.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Імпорт ====================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# === Завантаження датасету =====================\n",
        "url = \"https://raw.githubusercontent.com/ilchukjulia059-cyber/NeuroLabs/refs/heads/main/Lab2/df_file.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Встановлюємо назви колонок\n",
        "df.columns = ['text', 'label']\n",
        "\n",
        "# === Очищення тексту ==========================\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \" \", text)\n",
        "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
        "    tokens = [w for w in text.split() if len(w) > 2]  # простий токенізатор\n",
        "    return tokens\n",
        "\n",
        "df['tokens'] = df['text'].apply(clean_text)\n",
        "\n",
        "# === Створення словника ========================\n",
        "MAX_VOCAB = 20000\n",
        "specials = [\"[PAD]\", \"[UNK]\"]\n",
        "counter = Counter()\n",
        "for tok_list in df[\"tokens\"]:\n",
        "    counter.update(tok_list)\n",
        "\n",
        "most_common = counter.most_common(MAX_VOCAB - len(specials))\n",
        "itos = specials + [w for w, _ in most_common]\n",
        "stoi = {w: i for i, w in enumerate(itos)}\n",
        "PAD_IDX = stoi[\"[PAD]\"]\n",
        "UNK_IDX = stoi[\"[UNK]\"]\n",
        "\n",
        "def encode(tokens):\n",
        "    return [stoi.get(t, UNK_IDX) for t in tokens]\n",
        "\n",
        "MAX_LEN = 100\n",
        "def pad_sequence(seq):\n",
        "    seq = seq[:MAX_LEN] + [PAD_IDX] * max(0, MAX_LEN - len(seq))\n",
        "    return torch.tensor(seq, dtype=torch.long)\n",
        "\n",
        "df['encoded'] = df['tokens'].apply(encode)\n",
        "X = torch.stack(df['encoded'].apply(pad_sequence).tolist())\n",
        "y = torch.tensor(df['label'].values, dtype=torch.long)\n",
        "\n",
        "# === Dataset / DataLoader ======================\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "dataset = TextDataset(X, y)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64)\n",
        "\n",
        "# === Модель BiLSTM =============================\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_classes, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out, (h, c) = self.lstm(x)\n",
        "        h_cat = torch.cat([h[-2], h[-1]], dim=1)\n",
        "        return self.fc(h_cat)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def evaluate_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            preds = model(xb).argmax(dim=1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "    return 100 * correct / total\n",
        "\n",
        "# === Модель A: випадкові embedding ==============\n",
        "vocab_size = len(stoi)\n",
        "num_classes = df['label'].nunique()\n",
        "model_a = BiLSTM(vocab_size, emb_dim=100, hidden_dim=64, num_classes=num_classes, pad_idx=PAD_IDX).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_a = torch.optim.Adam(model_a.parameters(), lr=1e-3)\n",
        "\n",
        "train_loss_a, val_loss_a, accs_a = [], [], []\n",
        "start_a = time.time()\n",
        "for epoch in range(5):\n",
        "    model_a.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer_a.zero_grad()\n",
        "        out = model_a(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer_a.step()\n",
        "        total_loss += loss.item()\n",
        "    train_loss_a.append(total_loss / len(train_loader))\n",
        "    val_acc = evaluate_accuracy(model_a, val_loader)\n",
        "    accs_a.append(val_acc)\n",
        "    print(f\"[A {epoch+1}] train_loss={train_loss_a[-1]:.4f} | val_acc={val_acc:.2f}%\")\n",
        "time_a = time.time() - start_a\n",
        "acc_a = evaluate_accuracy(model_a, val_loader)\n",
        "print(f\"\\nТочність моделі A (random embedding): {acc_a:.2f}%\")\n",
        "\n",
        "# === Модель B: GloVe embedding =================\n",
        "# Завантажити свій GloVe файл (наприклад 100d)\n",
        "glove_path = \"/content/glove/glove.6B.100d.txt\"  # замініть на свій шлях\n",
        "def load_glove(path):\n",
        "    vectors = {}\n",
        "    with open(path, \"r\", encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            parts = line.rstrip().split(\" \")\n",
        "            word = parts[0]\n",
        "            vec = np.asarray(parts[1:], dtype=np.float32)\n",
        "            vectors[word] = vec\n",
        "    dim = len(next(iter(vectors.values())))\n",
        "    return vectors, dim\n",
        "\n",
        "# Якщо GloVe є\n",
        "glove, emb_dim = load_glove(glove_path)\n",
        "emb_matrix = np.random.normal(scale=0.1, size=(len(stoi), emb_dim)).astype(np.float32)\n",
        "emb_matrix[PAD_IDX] = 0.0\n",
        "hit = 0\n",
        "for w, idx in stoi.items():\n",
        "    v = glove.get(w)\n",
        "    if v is not None:\n",
        "        emb_matrix[idx] = v\n",
        "        hit += 1\n",
        "print(f\"GloVe coverage: {hit}/{len(stoi)} = {hit/len(stoi):.1%}\")\n",
        "\n",
        "pretrained_emb = nn.Embedding.from_pretrained(torch.tensor(emb_matrix), freeze=False, padding_idx=PAD_IDX).to(device)\n",
        "model_b = BiLSTM(len(stoi), emb_dim, 64, num_classes, PAD_IDX).to(device)\n",
        "model_b.embedding = pretrained_emb\n",
        "optimizer_b = torch.optim.Adam(model_b.parameters(), lr=1e-3)\n",
        "\n",
        "train_loss_b, accs_b = [], []\n",
        "start_b = time.time()\n",
        "for epoch in range(5):\n",
        "    model_b.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer_b.zero_grad()\n",
        "        out = model_b(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer_b.step()\n",
        "        total_loss += loss.item()\n",
        "    train_loss_b.append(total_loss / len(train_loader))\n",
        "    val_acc = evaluate_accuracy(model_b, val_loader)\n",
        "    accs_b.append(val_acc)\n",
        "    print(f\"[B {epoch+1}] train_loss={train_loss_b[-1]:.4f} | val_acc={val_acc:.2f}%\")\n",
        "time_b = time.time() - start_b\n",
        "acc_b = evaluate_accuracy(model_b, val_loader)\n",
        "print(f\"\\nТочність моделі B (GloVe embedding): {acc_b:.2f}%\")\n",
        "\n",
        "# === Порівняння =================================\n",
        "print(\"\\n--- Порівняння моделей ---\")\n",
        "print(f\"{'Метод':<20} {'Точність (%)':<15} {'Час навчання (с)':<18}\")\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'A: Random Embedding':<20} {acc_a:.2f}           {time_a:.2f}\")\n",
        "print(f\"{'B: GloVe Embedding':<20} {acc_b:.2f}           {time_b:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YSwdrwgdTCU",
        "outputId": "3389316f-8844-4c7e-b458-e0dc3c5633a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[A 1] train_loss=1.5933 | val_acc=30.56%\n",
            "[A 2] train_loss=1.4892 | val_acc=34.38%\n",
            "[A 3] train_loss=1.3090 | val_acc=47.87%\n",
            "[A 4] train_loss=0.9255 | val_acc=64.72%\n",
            "[A 5] train_loss=0.5221 | val_acc=70.56%\n",
            "\n",
            "Точність моделі A (random embedding): 70.56%\n",
            "GloVe coverage: 19600/20000 = 98.0%\n",
            "[B 1] train_loss=1.3799 | val_acc=79.78%\n",
            "[B 2] train_loss=0.5184 | val_acc=90.34%\n",
            "[B 3] train_loss=0.2662 | val_acc=88.09%\n",
            "[B 4] train_loss=0.2187 | val_acc=95.28%\n",
            "[B 5] train_loss=0.1286 | val_acc=95.96%\n",
            "\n",
            "Точність моделі B (GloVe embedding): 95.96%\n",
            "\n",
            "--- Порівняння моделей ---\n",
            "Метод                Точність (%)    Час навчання (с)  \n",
            "-------------------------------------------------------\n",
            "A: Random Embedding  70.56           25.70\n",
            "B: GloVe Embedding   95.96           23.36\n"
          ]
        }
      ]
    }
  ]
}